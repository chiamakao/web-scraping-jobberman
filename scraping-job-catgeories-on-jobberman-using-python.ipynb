{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Featured Jobs on jobberman.com using Python\n",
    "\n",
    "\n",
    "![banner-image](https://i.imgur.com/s6UkuCC.png)\n",
    "\n",
    "[Jobberman](https://www.jobberman.com) is a popular online jobs platform in Nigeria that connects qualified professionals to their dream jobs and employers to the best talent. Over 2 million people each year use jobberman to find jobs. The website homepage has a clean layout where job seekers can search for a job based on different categories. For each category, various jobs are featured.For example the [Sales](https://www.jobberman.com/jobs/sales) category, has different roles like `Sales Manager`, `Investment Advisor` and `Sales Representative`. \n",
    "\n",
    "\n",
    "In this project, we will retrieve information from this job category [Accounting, Auditing & Finance](https://www.jobberman.com/jobs/accounting-auditing-finance) using a technique called _web scraping_.\n",
    "\n",
    "\n",
    "**What is Web Scraping?**\n",
    "\n",
    "Letâ€™s assume you want to collect a line of information from a website, what do you do? The first line of action would be to copy and paste this information, but what if you want to collect a large amount of information running into hundreds of pages as quickly as possible, do you think you would be able to achieve this by manually copying and pasting? This is where web scraping comes in! By using simple libraries, the process of web scraping allows you to extract data from a website in an automated fashion using code. Most of this data is unstructured and in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "\n",
    "So, when a web scraper needs to scrape a site, first the URL is provided, then it loads all the HTML code for the site. The scraper then obtains the required data from this HTML code and outputs this data in the format specified by the user. Mostly, this is in the form of an Excel spreadsheet or a CSV file, but the data can also be saved in other formats, such as a JSON file.\n",
    "\n",
    "\n",
    "Here's an outline of the steps we'll follow.\n",
    "1. Download the webpage using Requests\n",
    "2. Parse the HTML source code using Beautiful Soup\n",
    "3. Extract featured jobs from each job category\n",
    "4. Compile extracted information into Python dictionaries\n",
    "5. Extract and combine data from multiple pages\n",
    "6. Save the extracted information to a CSV file\n",
    "\n",
    "By the end of the project, we will create a CSV in the following format:\n",
    "\n",
    "```\n",
    "Job_Url,job_Title,Company\n",
    "https://www.jobberman.com/listings/accountant-rvwnq9,Accountant,Jobberman (Third Party Recruitment)\n",
    "https://www.jobberman.com/listings/investment-principal-5xn457,Investment Principal,Jobberman (Third Party Recruitment)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  How to run the code\n",
    "\n",
    "You can execute the code by selecting the \"Run\" button at the top of this page. You can make changes and save your own version to [Jovian](https://jovian.ai/) by executing the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"scraping-job-catgeories-on-jobberman-using-python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the webpage using Requests\n",
    "\n",
    "We can use the `requests` library to download the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library is now installed and imported\n",
    "\n",
    "To download a page we can use the `get` function from requests, which returns a response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url = 'https://www.jobberman.com/jobs/accounting-auditing-finance'\n",
    "response = requests.get(topic_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.status_code` property can be used to check if the response was successful. If the request was successful, `response.status_code` is set to a value between 200 and 299."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response was successful. The contents of the web page can then be accessed using the `.text` property of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of characters on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172806"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page contains over 150,000 characters! Let's view the first 500 characters of the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"no-js scroll-smooth\" lang=\"en-ng\">\\n<head>\\n<meta charset=\"utf-8\" />\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\\n<meta name=\"google-site-verification\" content=\"4hClu3W3PtjepabInbxYOahjMMOlzUNqWBY9OKZJtdA\" />\\n<meta name=\"csrf-token\" content=\"1xU1AR4ZpMrKHgfAhvnjvT5ojFRs2tte6Gc5GzYO\">\\n<link rel=\"prerender\" href=\"https://www.jobberman.com/listings/financial-accountant-6kjm6p\">\\n<link rel=\"prerender\" href=\"https://www.jobberman.com'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see above is the source code of the web page. It's written in a language called [HTML](https://www.w3schools.com/html/). It defines the content and structure of the web page.\n",
    "\n",
    "Let's save the contents to a file with the `.html` extension. This page can also be viewed locally within Jupyter using 'File > Open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('job-in-nigeria.html', 'w') as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we successfully downloaded a web page using `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=\"scraping-job-catgeories-on-jobberman-using-python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the HTML source code using Beautiful Soup\n",
    "\n",
    "To extract information from the HTML source code of a webpage programmatically, we can use the Beautiful Soup library. \n",
    "\n",
    "Let's install the library and import the BeautifulSoup class from the bs4 module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully installed and imported beautiful soup, let's now call it on the contents of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A beautiful soup object `doc` is then created. The doc object contains several properties and methods for extracting information from the HTML document. To view the source code of any webpage on your browser, right-click anywhere on a page and select the \"Inspect\" option. It opens the \"Developer Tools\" pane, where you can see the source code as a tree. You can expand and collapse various nodes and find the source code for a specific portion of the page.Let's look at a few examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the type of doc using the `type` function to confirm that it is a beautiful soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate how beautiful soup works by retrieving the title of the page which is contained within the `h1` tag.\n",
    "\n",
    "![](https://i.imgur.com/MLVJbb8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"flex-grow-0 flex-shrink-0 mb-7 text-2xl font-medium text-gray-700 capitalize basis-full\">Accounting, auditing &amp; finance jobs in Nigeria</h1>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the first embedded image on the web page, using the `img` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img alt=\"Jobberman\" class=\"mr-10 lazyload\" src=\"https://www.jobberman.com/static-assets/img/ng/landscape.svg\" width=\" 180 \"/>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all the occurrences of `a` tag (which represents a link), use the find_all method. To find the first occurrence use the find method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment this and run the cell to view the output\n",
    "\n",
    "#doc.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes of a tag can be accessed using the indexing notation, e.g., doc.a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jobberman.com'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the first two sections, we can now define a helper function to download the web page and return a beautifulsoup doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print('Status code:', response.status_code)\n",
    "        raise Exception('Failed to fetch web page {}'.format(url))\n",
    "    page_contents = response.text    \n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the function `job_page()` to download any web page and parse it using beautiful soup. \n",
    "\n",
    "Now, getting web pages of different job catgeories is now as simple as invoking the function with a different argument. Let's show the usage of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = job_page(topic_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the title of the page to ensure we have the right page. We will use the `text` method to access the text within the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accounting, auditing & finance jobs in Nigeria'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('h1').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been able to install and import the beautiful soup library which we used to parse our web page, and we have created a reusable function which captures the process of downloading any web page and extracting information from it using beautiful soup. The function captures both the functionalities of the first and second section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=\"scraping-job-catgeories-on-jobberman-using-python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract featured jobs from a job category\n",
    "\n",
    "We are now able to parse through web pages so let's go ahead and extract the various job listings under each job category. We will be collecting information about the job title, job url and company.\n",
    "\n",
    "Now, upon inspecting the box containing the information for a job listing, you will find a `div` tag for each listing, with `class` attribute set to 'mx-5 md:mx-0 flex flex-wrap col-span-1 mb-5 bg-white rounded-lg border border-gray-300 hover:border-gray-400 focus-within:ring-2 focus-within:ring-offset-2 focus-within:ring-gray-500'.\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/FZ561or.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find all the `div` tags matching this `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tags = doc.find_all('div', class_= 'mx-5 md:mx-0 flex flex-wrap col-span-1 mb-5 bg-white rounded-lg border border-gray-300 hover:border-gray-400 focus-within:ring-2 focus-within:ring-offset-2 focus-within:ring-gray-500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the number of div_tags on this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(div_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 19 job listings on the page, and our query resulted in 19 `div` tags. It looks like we've found the enclosing tag for each job listing.\n",
    "\n",
    "We need to extract the following information from each tag:\n",
    "\n",
    "1. Job Url\n",
    "2. Job Title\n",
    "3. Company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Url \n",
    "\n",
    "Let's retrieve the first `div` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tag = div_tags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the source of any of the `div` tags. You will notice that the job link is a part of an `a` tag with `class` attribute 'relative mb-3 text-lg font-medium break-words focus:outline-none metrics-apply-now text-brand-linked'.\n",
    "\n",
    "![](https://i.imgur.com/WN7FSQH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the first instance of an `a` tag with it's corresponding `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tag = div_tag.find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jobberman.com/listings/accountant-48gdmr'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the first instance of `a` tag has the link \"https://www.jobberman.com/listings/financial-analyst-0w68md\"\n",
    "\n",
    "Now let's find all instances of the `a` tags with corresponding `class`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function to capture all job urls on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_url(doc):\n",
    "    selector = 'relative mb-3 text-lg font-medium break-words focus:outline-none metrics-apply-now text-brand-linked'\n",
    "    a_tags = doc.find_all('a', {'class': selector})\n",
    "    return [tag['href'] for tag in a_tags]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an object of the function `get_job_url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_job_url(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of urls contained on the page, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we have 19 job urls for the 19 jobs posted on the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first five job urld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.jobberman.com/listings/accountant-48gdmr',\n",
       " 'https://www.jobberman.com/listings/finance-lead-rvx6k2',\n",
       " 'https://www.jobberman.com/listings/accountant-vejz8v',\n",
       " 'https://www.jobberman.com/listings/financial-accountant-6kjm6p',\n",
       " 'https://www.jobberman.com/listings/head-of-finance-administration-99vdmw']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Title\n",
    "\n",
    "The title of each job is contained within a `p` tag with `class` attribute 'text-lg font-medium break-words text-brand-linked'.\n",
    "\n",
    "![](https://i.imgur.com/SOQn4yQ.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract this information for all the jobs on the page lets create a helper function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_title(doc):\n",
    "    selector = 'text-lg font-medium break-words text-brand-linked'\n",
    "    p_tags = doc.find_all('p', {'class': selector})\n",
    "    return [tag.text.strip() for tag in p_tags]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an object of the function `get_job_title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_job_title(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of titles contained on the page, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we have 19 job titles for the 19 jobs posted on the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first five job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accountant',\n",
       " 'Finance Lead',\n",
       " 'Accountant',\n",
       " 'Financial Accountant',\n",
       " 'Head of Finance & Administration']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company\n",
    "\n",
    "Let's retrieve the name of the hiring company which is enclosed within a `p` tag with `class` 'text-sm text-brand-linked'.\n",
    "\n",
    "![](https://i.imgur.com/qDK5aSo.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a helper function to retrieve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company(doc):\n",
    "    selector = 'text-sm text-brand-linked'\n",
    "    p_tags = doc.find_all('p', {'class': selector})\n",
    "    return [tag.text.strip() for tag in p_tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an object of the function `get_company`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = get_company(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 19 hiring companies for the 19 jobs posted on the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first five companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stylish Hair and Beauty Studio Ltd',\n",
       " 'Jobberman (Third Party Recruitment)',\n",
       " 'Ayomo bakery',\n",
       " 'Xcene Research',\n",
       " 'Afos Foundation']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we identified all the tags containing the information we need to successfully scrape our website and we wrote helper functions to help retrieve these information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/olivelikes2chat/scraping-job-catgeories-on-jobberman-using-python'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=\"scraping-job-catgeories-on-jobberman-using-python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile extracted information into Python dictionaries\n",
    "\n",
    "Now, we have been able to extract all the information we need, let's put them into a dictionary. Where each key is a column and the data for the column is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_info = {'Job_Url': urls, \n",
    "            'Job_Title': titles, \n",
    "            'Company': companies\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now install and import the [pandas](https://pandas.pydata.org/docs/) library to convert the compiled dictionary into a dataframe. To do this, we wll use the `pd.DataFrame` function of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully installed and imported the `pandas` library. Now, let's view the information as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Url</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Stylish Hair and Beauty Studio Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.jobberman.com/listings/finance-lea...</td>\n",
       "      <td>Finance Lead</td>\n",
       "      <td>Jobberman (Third Party Recruitment)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Ayomo bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.jobberman.com/listings/financial-a...</td>\n",
       "      <td>Financial Accountant</td>\n",
       "      <td>Xcene Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.jobberman.com/listings/head-of-fin...</td>\n",
       "      <td>Head of Finance &amp; Administration</td>\n",
       "      <td>Afos Foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.jobberman.com/listings/accounts-of...</td>\n",
       "      <td>Accounts Officer</td>\n",
       "      <td>Alarm Center Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Anonymous Employer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Tender Years Preparatory School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.jobberman.com/listings/finance-off...</td>\n",
       "      <td>Finance Officer</td>\n",
       "      <td>SocketWorks Nigeria Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.jobberman.com/listings/account-man...</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>Teal Harmony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Radiance Shield Properties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.jobberman.com/listings/finance-man...</td>\n",
       "      <td>Finance Manager</td>\n",
       "      <td>Jobberman (Third Party Recruitment)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Jobberman (Third Party Recruitment)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.jobberman.com/listings/sme-loan-of...</td>\n",
       "      <td>SME Loan Officer</td>\n",
       "      <td>Next Empowerment Foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>CECILIA HOMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Top Notch Consults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.jobberman.com/listings/head-audit-...</td>\n",
       "      <td>Head Audit</td>\n",
       "      <td>Bakan Gizo Pharmarcy &amp; Store Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.jobberman.com/listings/7-accountan...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Bakan Gizo Pharmarcy &amp; Store Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.jobberman.com/listings/junior-fina...</td>\n",
       "      <td>Junior Financial &amp; Investment Analyst</td>\n",
       "      <td>Ullweb Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Job_Url  \\\n",
       "0   https://www.jobberman.com/listings/accountant-...   \n",
       "1   https://www.jobberman.com/listings/finance-lea...   \n",
       "2   https://www.jobberman.com/listings/accountant-...   \n",
       "3   https://www.jobberman.com/listings/financial-a...   \n",
       "4   https://www.jobberman.com/listings/head-of-fin...   \n",
       "5   https://www.jobberman.com/listings/accounts-of...   \n",
       "6   https://www.jobberman.com/listings/accountant-...   \n",
       "7   https://www.jobberman.com/listings/accountant-...   \n",
       "8   https://www.jobberman.com/listings/finance-off...   \n",
       "9   https://www.jobberman.com/listings/account-man...   \n",
       "10  https://www.jobberman.com/listings/accountant-...   \n",
       "11  https://www.jobberman.com/listings/finance-man...   \n",
       "12  https://www.jobberman.com/listings/accountant-...   \n",
       "13  https://www.jobberman.com/listings/sme-loan-of...   \n",
       "14  https://www.jobberman.com/listings/accountant-...   \n",
       "15  https://www.jobberman.com/listings/accountant-...   \n",
       "16  https://www.jobberman.com/listings/head-audit-...   \n",
       "17  https://www.jobberman.com/listings/7-accountan...   \n",
       "18  https://www.jobberman.com/listings/junior-fina...   \n",
       "\n",
       "                                Job_Title                              Company  \n",
       "0                              Accountant   Stylish Hair and Beauty Studio Ltd  \n",
       "1                            Finance Lead  Jobberman (Third Party Recruitment)  \n",
       "2                              Accountant                         Ayomo bakery  \n",
       "3                    Financial Accountant                       Xcene Research  \n",
       "4        Head of Finance & Administration                      Afos Foundation  \n",
       "5                        Accounts Officer                 Alarm Center Limited  \n",
       "6                              Accountant                   Anonymous Employer  \n",
       "7                              Accountant      Tender Years Preparatory School  \n",
       "8                         Finance Officer          SocketWorks Nigeria Limited  \n",
       "9                         Account Manager                         Teal Harmony  \n",
       "10                             Accountant           Radiance Shield Properties  \n",
       "11                        Finance Manager  Jobberman (Third Party Recruitment)  \n",
       "12                             Accountant  Jobberman (Third Party Recruitment)  \n",
       "13                       SME Loan Officer          Next Empowerment Foundation  \n",
       "14                             Accountant                        CECILIA HOMES  \n",
       "15                             Accountant                   Top Notch Consults  \n",
       "16                             Head Audit     Bakan Gizo Pharmarcy & Store Ltd  \n",
       "17                             Accountant     Bakan Gizo Pharmarcy & Store Ltd  \n",
       "18  Junior Financial & Investment Analyst                    Ullweb Technology  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(jobs_info)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the dataframe we have that there are 19 jobs on the page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and combine data from multiple pages\n",
    "\n",
    "Using a dictionary to convert to a dataframe is great, however, it can only be used for one page. \n",
    "\n",
    "Putting it all together, let's create a function that will help us extract the same information(job url, job title, company) from all the pages. The function will work by using beautiful soup to parse through all the pages on the web page to retrieve individual information about the url, title and company of all the jobs listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pages(page_number):\n",
    "    url = 'https://www.jobberman.com/jobs/accounting-auditing-finance?page=' + str(page_number)\n",
    "    doc = job_page(url)\n",
    "    urls = get_job_url(doc)\n",
    "    titles = get_job_title(doc)\n",
    "    companies = get_company(doc)\n",
    "    return urls, titles, companies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create empty lists of all the titles,urls and companies on all the pages and then run a for loop to go through every page and collect information to fill up our lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls, all_titles, all_companies = [], [], []\n",
    "\n",
    "for page_number in range(2, 8):\n",
    "    urls, titles, companies = get_all_pages(page_number)\n",
    "    all_urls += urls\n",
    "    all_titles += titles\n",
    "    all_companies += companies\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dictionary using the lists we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_all_pages = {'Job_Url': all_urls, \n",
    "                'Job_Title': all_titles, \n",
    "                'Company': all_companies, \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then create a dataframe using `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Url</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Stylish Hair and Beauty Studio Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.jobberman.com/listings/finance-lea...</td>\n",
       "      <td>Finance Lead</td>\n",
       "      <td>Jobberman (Third Party Recruitment)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Ayomo bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>JTech Global Resources Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.jobberman.com/listings/accountant-...</td>\n",
       "      <td>Accountant/ Cost Accountant</td>\n",
       "      <td>NCIC Oil Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>https://www.jobberman.com/listings/team-lead-f...</td>\n",
       "      <td>Team Lead, Fraud Desk</td>\n",
       "      <td>Teamapt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>https://www.jobberman.com/listings/field-credi...</td>\n",
       "      <td>Field Credit Risk Officer</td>\n",
       "      <td>Teamapt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>https://www.jobberman.com/listings/bank-sales-...</td>\n",
       "      <td>Bank Sales Manager (Cross River)</td>\n",
       "      <td>Teamapt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>https://www.jobberman.com/listings/moniepoint-...</td>\n",
       "      <td>MONIEPOINT CUSTOMER SUCCESS (KWARA STATE)</td>\n",
       "      <td>Teamapt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>https://www.jobberman.com/listings/market-inte...</td>\n",
       "      <td>Market Intelligence Analyst</td>\n",
       "      <td>Teamapt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Job_Url  \\\n",
       "0    https://www.jobberman.com/listings/accountant-...   \n",
       "1    https://www.jobberman.com/listings/finance-lea...   \n",
       "2    https://www.jobberman.com/listings/accountant-...   \n",
       "3    https://www.jobberman.com/listings/accountant-...   \n",
       "4    https://www.jobberman.com/listings/accountant-...   \n",
       "..                                                 ...   \n",
       "106  https://www.jobberman.com/listings/team-lead-f...   \n",
       "107  https://www.jobberman.com/listings/field-credi...   \n",
       "108  https://www.jobberman.com/listings/bank-sales-...   \n",
       "109  https://www.jobberman.com/listings/moniepoint-...   \n",
       "110  https://www.jobberman.com/listings/market-inte...   \n",
       "\n",
       "                                     Job_Title  \\\n",
       "0                                   Accountant   \n",
       "1                                 Finance Lead   \n",
       "2                                   Accountant   \n",
       "3                                   Accountant   \n",
       "4                  Accountant/ Cost Accountant   \n",
       "..                                         ...   \n",
       "106                      Team Lead, Fraud Desk   \n",
       "107                  Field Credit Risk Officer   \n",
       "108           Bank Sales Manager (Cross River)   \n",
       "109  MONIEPOINT CUSTOMER SUCCESS (KWARA STATE)   \n",
       "110                Market Intelligence Analyst   \n",
       "\n",
       "                                 Company  \n",
       "0     Stylish Hair and Beauty Studio Ltd  \n",
       "1    Jobberman (Third Party Recruitment)  \n",
       "2                           Ayomo bakery  \n",
       "3             JTech Global Resources Ltd  \n",
       "4                       NCIC Oil Service  \n",
       "..                                   ...  \n",
       "106                              Teamapt  \n",
       "107                              Teamapt  \n",
       "108                              Teamapt  \n",
       "109                              Teamapt  \n",
       "110                              Teamapt  \n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(jobs_all_pages)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully scraped 8 pages from the `\n",
    "Accounting, Auditing & Finance` web page and converted into a dataframe which contains 3 columns and 111 rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the extracted information to a csv file\n",
    "\n",
    "To save the dataframe to a `csv` file, we simply call the `dataframe.to_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('accounting.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read the file and inspect its contents. The contents of the file can also be inspected using the \"File > Open\" menu option within Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this project, we have been able to extract information about featured jobs by using python libraries and creating helper functions. We also used these functions to collect information from multiple pages of the job website and compiled it into a python dictionary. The dictionary was then converted into a pandas data frame and saved as a CSV file that can be used in various applications.\n",
    "\n",
    "The CSV file we created had this format:\n",
    "\n",
    "```\n",
    "Job_Url,job_Title,Company\n",
    "https://www.jobberman.com/listings/accountant-rvwnq9,Accountant,Jobberman (Third Party Recruitment)\n",
    "https://www.jobberman.com/listings/investment-principal-5xn457,Investment Principal,Jobberman (Third Party Recruitment)\n",
    "...\n",
    "```\n",
    "Here's the full working code for this project:\n",
    "```\n",
    "all_urls, all_titles, all_companies = [], [], []\n",
    "\n",
    "for page_number in range(2, 9):\n",
    "    urls, titles, companies = get_all_pages(page_number)\n",
    "    all_urls += urls\n",
    "    all_titles += titles\n",
    "    all_companies += companies\n",
    "    \n",
    "def get_all_pages(page_number):\n",
    "    url = 'https://www.jobberman.com/jobs/accounting-auditing-finance?page=' + str(page_number)\n",
    "    doc = job_page(url)\n",
    "    urls = get_job_url(doc)\n",
    "    titles = get_job_title(doc)\n",
    "    companies = get_company(doc)\n",
    "    return urls, titles, companies\n",
    "\n",
    "def get_company(doc):\n",
    "    selector = 'text-sm text-brand-linked'\n",
    "    p_tags = doc.find_all('p', {'class': selector})\n",
    "    return [tag.text.strip() for tag in p_tags]\n",
    "\n",
    "def get_job_title(doc):\n",
    "    selector = 'text-lg font-medium break-words text-brand-linked'\n",
    "    p_tags = doc.find_all('p', {'class': selector})\n",
    "    return [tag.text.strip() for tag in p_tags]\n",
    "    \n",
    "def get_job_url(doc):\n",
    "    selector = 'relative mb-3 text-lg font-medium break-words focus:outline-none metrics-apply-now text-brand-linked'\n",
    "    a_tags = doc.find_all('a', {'class': selector})\n",
    "    return [tag['href'] for tag in a_tags]\n",
    "    \n",
    "def job_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print('Status code:', response.status_code)\n",
    "        raise Exception('Failed to fetch web page {}'.format(url))\n",
    "    page_contents = response.text    \n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc\n",
    "```    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "1. Exploring all jobs category and scraping all jobs at once to make a list of all the jobs available on the Jobberman website\n",
    "2. Fetching job data from other job listing companies in Nigeria, such as Philips Consulting, and creating a job aggregator website where job seekers can easily find a comprehensive list of jobs.\n",
    "3. Data fetched can be used for analyzing job trends and the labor market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Here are some links that helped in the completion of this project:\n",
    "\n",
    "1. https://www.jobberman.com/\n",
    "2. https://www.freecodecamp.org/news/web-scraping-python-tutorial-how-to-scrape-data-from-a-website/\n",
    "3. https://realpython.com/python-requests/\n",
    "4. https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "5. https://www.w3schools.com/html/\n",
    "7. https://pandas.pydata.org/docs/\n",
    "8. https://www.jobberman.com/jobs/accounting-auditing-finance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jovian.commit(files=['accounting.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
